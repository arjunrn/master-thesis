\chapter{Introduction}

\section{Motivation}

Distributed Coordination Services are a critical component of many distributed applications. There have been several implementations of such algorithms in the past. Google published a paper on an internal service called Chubby~\cite{burrows2006chubby}. This sparked an interest in using similar services in other distributed application. ZooKeeper~\cite{hunt2010zookeeper} was developed by Yahoo to replicate some the functionality of Chubby. ZooKeeper was implemented in Java and is today maintained by the Apache Software Foundation. It is also a component in other distributed frameworks like Hadoop~\cite{white2009hadoop} and Cassandra~\cite{lakshman2010cassandra}. There have been other implementations of coordination services like Doozer~\cite{ketelsen2015doozerd} and etcd~\cite{coreos2015etcd}. These projects are relatively new and are based on the Raft~\cite{ongaro2013search} consensus protocol which is not extensively deployed in working systems. 

The scale and size of distributed applications increases everyday. Coordination services like ZooKeeper need to keep up with this increasing traffic demands. The throughput rate of ZooKeeper is limited by three main factors:

\begin{enumerate}
	\item Local Disk Throughput
	\item Network Speed
	\item Local Processing Capacity.
\end{enumerate}

For every write operation the ZooKeeper cluster requires a consensus between a quorum number of member nodes which agree on the proposed update, process it and finally acknowledge that they have committed the change. This slows down the response time. However the number of connected clients and the fault-tolerance of the cluster can be scaled only by increasing the number of servers in the ZooKeeper cluster, that is the number of nodes participating in the consensus. These competing but opposing forces makes scaling the throughput of ZooKeeper difficult. 

We try to solve these problem by partitioning the data which would be normally held by a single cluster and distributing them among a number of ZooKeeper clusters. We also implement this solution completely on the client-side, so that it does not necessitate any modification to the the ZooKeeper source code. The client library is implemented in such a way that the consistency properties of ZooKeeper are also upheld.

At this point, it has to be mentioned that this solution is not an attempt to reinvent consensus algorithms. It attempts to solve a problem using existing time-tried technologies and concepts. ZooKeeper has been deployed in several large scale projects and there exists bindings to connect to ZooKeeper in several programming languages. There also exists a large body of documentation supporting the use and deployment of ZooKeeper. It's also based on Java which is a common choice for large applications. This solutions attempts to provide a solution for existing distributed applications which require higher throughput than what can be currently provided by the ordinary ZooKeeper cluster.

\section{Structure of Thesis}

\textit{Chapter 2} discusses the related work around coordination services and consensus algorithms. It introduces some of the motivations and the intentions for the implementing ZooKeeper.

\textit{Chapter 3} introduces ZooKeeper which is the backbone of the proposed solution. It explains important concepts like how data is stored in ZooKeeper and the common operations.

\textit{Chapter 4} explains the implementation of ParKazoo. All of operations which are implemented are explained in detail.

In \textit{Chapter 5} the tests which are used to confirm the functionality of ParKazoo are explained. Some tests from Kazoo which are reused to confirm the functionality of ParKazoo are also discussed.

\textit{Chapter 6} is the Evaluation chapter which discusses the results of testing the Throughput and the Latency of ParKazoo against the original ZooKeeper.

\textit{Chapter 7} describes some of the limitations in the proposed solution.

\textit{Chapter 8} proposes improvements which could be implemented but are out of the scope of the current thesis.
