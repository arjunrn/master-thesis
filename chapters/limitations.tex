\chapter{Limitations}

\section{Data Inconsistency}

\input{diagrams/data_inconsistency.tex}

Not all operations are completely data safe. The recursive data operation is an example of such an operation. The delete() operation iterates over the client connections and then deletes the subtrees. Assume that the client crashes after deleting the subtrees only a few clusters. Then if one of the nodes which is missing then the whole tree gets recreated. So a node which is supposed to be deleted still exists. Figure~\ref{fig:recDelInconsistency} shows how inconsistency can be caused by the recursive \textit{delete()} operation. In the first step there is a node \textit{/node1/p\_1} which is on a cluster shown on the right. The cluster on the left contains the parent node \textit{/node1}. If the recursive delete operation deletes the parent node first and crashes then the node \textit{/node1/p\_1} still exists. If the node \textit{/node1} is created again then the child gets automatically created.

\section{Ordering of Operations}
ZooKeeper provides the guarantee of client operation order. This means that all the operations which are issues by a client are executed in the order they are sent to the server. But with ParKazoo this assumptions will not hold true. Assume 2 operations issued by a client. The first operation is mapped to one cluster and the second operation gets mapped to another cluster. If the operations are issued one after the other in a normal ZooKeeper operation the result of the first operation is returned first. But with ParKazoo the result of the first operation could be returned first because the operations are executed on different clusters.

\section{Limited Client Connections}
The evaluation tests revealed that there is a natural limit to the number of connected clients. Although in a production system it is would quite uncommon to have so many clients this still is a limiting factor for the throughput of the entire system.
